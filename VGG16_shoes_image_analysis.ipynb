{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "from keras.applications import vgg16\n",
    "from IPython.display import display # 이미지 출력 함수\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/gdrive/My Drive/Colab Notebooks/dataset/shoes_data/train'\n",
    "validation_dir = '/gdrive/My Drive/Colab Notebooks/dataset/shoes_data/test'\n",
    "batch_size = 32\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습에 사용될 이미지 데이터 생성기, 이미지 데이터 증강\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 180 , #회전 최대 20도\n",
    "    width_shift_range = 0.2, #좌우 이동\n",
    "    height_shift_range = 0.2, # 상하 이동\n",
    "    horizontal_flip = True, # 좌우 반전\n",
    "    vertical_flip=True, # 상하 반전\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증에 사용될 이미지 데이터 생성기\n",
    "validation_datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(image_size,image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= 'categorical',\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=len(train_generator.class_indices)\n",
    "\n",
    "custom_labels = list(validation_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 새롭게 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() # 새로운 세션으로 시작\n",
    "\n",
    "#모델 불러오기\n",
    "conv_layers = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
    "conv_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution layer를 학습되지 않도록 고정\n",
    "for layer in conv_layers.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 모델 생성하기\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 모델의 convolution layer 추가\n",
    "model.add(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 Fully connected 부분을 재구성\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(class_num, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "vgg16_model_path = 'new_train_from_vgg16.h5'\n",
    "model.save(vgg16_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(vgg16_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.download(vgg16_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습률과 손실 확인\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='accuracy')\n",
    "plt.plot(epochs, loss, 'r', label='loss')\n",
    "plt.title('accuracy and loss')\n",
    "plt.legend()\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(vgg16_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장시킨 모델로 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "vgg16_model_path = '/gdrive/My Drive/Colab Notebooks/new_train_from_vgg16.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/gdrive/My Drive/Colab Notebooks/new_train_from_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류코드 (기존 모델용)\n",
    "\n",
    "def predict_vgg16(model, filename) :\n",
    "    image = load_img(filename) #이미지 파일을 읽고 화면에 표시\n",
    "    # image = PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=688x550\n",
    "    display(image)\n",
    "    \n",
    "    image = load_img(filename, target_size=(224, 224)) #모델 사이즈로 이미지 파일 읽기\n",
    "    # image = PIL.Image.Image image mode=RGB size=224x224\n",
    "    \n",
    "    image = img_to_array(image) #이미지 데이터를 numpy로 변환\n",
    "    \n",
    "    image = image.reshape((1, 224, 224, 3))\n",
    "    #vgg16.preprocess_input()을 호출하기 위해 차원을 조정\n",
    "    #보통 모델을 여러 이미지를 한번에 호출\n",
    "    #맨앞의 1 = 이미지 갯수 1, 224 가로세로, 네번쨰 R,G,B 3개\n",
    "    \n",
    "    image = vgg16.preprocess_input(image)\n",
    "    # Vgg16 모델 호출 위한 전처리\n",
    "    # -255~255 사이 값으로 정규화\n",
    "    # RGB를 BGR순으로 바꾼다\n",
    "    \n",
    "    yhat = model.predict(image) #이미지를 모델에 적용\n",
    "    label = vgg16.decode_predictions(yhat) # 모델 적용된 결과를 파싱\n",
    "    label = label[0][0] # 가장 확률이 높은 결과를 휙득\n",
    "    print('%s (%.2f%%)' % (label[1], label[2]*100)) #라벨과 라벨을 예측한 확률을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe(filename) :\n",
    "    image = load_img(filename) #이미지 파일을 읽고 화면에 표시\n",
    "    # image = PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=688x550\n",
    "    display(image)\n",
    "    \n",
    "    image = load_img(filename, target_size=(224, 224)) #모델 사이즈로 이미지 파일 읽기\n",
    "    # image = PIL.Image.Image image mode=RGB size=224x224\n",
    "    \n",
    "    image = img_to_array(image) #이미지 데이터를 numpy로 변환\n",
    "    \n",
    "    image = image.reshape((1, 224, 224, 3))\n",
    "    #vgg16.preprocess_input()을 호출하기 위해 차원을 조정\n",
    "    #보통 모델을 여러 이미지를 한번에 호출\n",
    "    #맨앞의 1 = 이미지 갯수 1, 224 가로세로, 네번쨰 R,G,B 3개\n",
    "    \n",
    "    image = vgg16.preprocess_input(image)\n",
    "    # Vgg16 모델 호출 위한 전처리\n",
    "    # -255~255 사이 값으로 정규화\n",
    "    # RGB를 BGR순으로 바꾼다\n",
    "    feature = model.predict(image)[0]\n",
    "    return feature / np.linalg.norm(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "img_paths = []\n",
    "\n",
    "# Save Image Feature Vector with Database Images\n",
    "for i in range(1, 3000):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        image_path = '/gdrive/My Drive/Colab Notebooks/dataset/shoes_data/shoesCNN/' + str(i) + \".jpg\"\n",
    "        img_paths.append(image_path)\n",
    "\n",
    "        # Extract Features\n",
    "        feature = fe(image_path)\n",
    "\n",
    "        features.append(feature)\n",
    "\n",
    "        # Save the Numpy array (.npy) on designated path\n",
    "        feature_path = '/gdrive/My Drive/Colab Notebooks/dataset/shoes_data/shoesCNN/' + str(i) + \".npy\"\n",
    "        np.save(feature_path, feature)\n",
    "    except Exception as e:\n",
    "        print('예외가 발생했습니다.', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/gdrive/My Drive/Colab Notebooks/random.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract its features\n",
    "query = fe(test_path)\n",
    "\n",
    "# Calculate the similarity (distance) between images\n",
    "dists = np.linalg.norm(features - query, axis=1)\n",
    "\n",
    "# Extract 30 images that have lowest distance\n",
    "ids = np.argsort(dists)[:4]\n",
    "\n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(4):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + str(score[2]+1)\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(load_img(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
